---
title: "Dynamic Linear Models"
subtitle: "FISH 507 â€“ Applied Time Series Analysis"
author: "Mark Scheuerell"
date: "5 Feb 2019"
output:
  ioslides_presentation:
    css: lecture_slides.css
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(kableExtra)
set.seed(123)
```

## Topics for today




## Simple linear regression

Let's begin with a linear regression model

$$
y_i = \alpha + \beta x_i + e_i ~ \text{with} ~ e_i \sim \text{N}(0,\sigma^2)
$$

The index $i$ has no explicit meaning--shuffling ($y_i,x_i$) pairs has no effect on parameter estimation


## Simple linear regression

We can write the model in matrix form

$$
y_i = \alpha + \beta x_i + e_i \\
\Downarrow \\
y_i = 
\begin{bmatrix}
  1 & x_i
\end{bmatrix}
\begin{bmatrix}
  \alpha \\
  \beta
\end{bmatrix} +
e_i
$$


## Simple linear regression

We can write the model in matrix form

$$
y_i = \alpha + \beta x_i + e_i \\
\Downarrow \\
y_i = 
\begin{bmatrix}
  1 & x_i
\end{bmatrix}
\begin{bmatrix}
  \alpha \\
  \beta
\end{bmatrix} +
e_i \\
\Downarrow \\
y_i = \mathbf{X}^{\top}_i \mathbf{\Theta} + e_i
$$

with $\mathbf{X}^{\top}_i = \begin{bmatrix} 1 & x_i \end{bmatrix}$ and $\mathbf{\Theta} = \begin{bmatrix} \alpha & \beta \end{bmatrix}^{\top}$ 


## Dynamic linear model (DLM)

In a _dynamic_ linear model, the regression parameters change over time, so we write

$$
y_i = \mathbf{X}^{\top}_i \mathbf{\Theta} + e_i ~~~~~~~ \text{(static)}
$$

as

$$
y_t = \mathbf{X}^{\top}_t \mathbf{\Theta}_t + e_t ~~~~~~~ \text{(dynamic)}
$$


## Dynamic linear model (DLM)

There are 2 important points here:

$$
y_\boxed{t} = \mathbf{X}^{\top}_t \mathbf{\Theta}_t + e_t
$$

1. Subscript $t$ explicitly acknowledges implicit info in the time ordering of the data in $\mathbf{y}$  


## Dynamic linear model (DLM)

There are 2 important points here:

$$
y_t = \mathbf{X}^{\top}_t \mathbf{\Theta}_\boxed{t} + e_t
$$

1. Subscript $t$ explicitly acknowledges implicit info in the time ordering of the data in $\mathbf{y}$  

2. The relationship between $\mathbf{y}$ and $\mathbf{X}$ is unique for every $t$


## Constraining a DLM

Close examination of the DLM reveals an apparent problem for parameter estimation

$$
y_t = \mathbf{X}^{\top}_t \mathbf{\Theta}_\boxed{t} + e_t
$$


## Constraining a DLM

Close examination of the DLM reveals an apparent problem for parameter estimation

$$
y_t = \mathbf{X}^{\top}_t \mathbf{\Theta}_t + e_t
$$

We only have 1 data point per time step (ie, $y_t$ is a scalar)

__Thus, we can only estimate 1 parameter (with no uncertainty)!__


## Constraining a DLM

To address this issue, we'll constrain the regression parameters to be dependent from $t$ to $t+1$

$$
\mathbf{\Theta}_t = \mathbf{G}_t \mathbf{\Theta}_{t-1} + \mathbf{w}_t ~ \text{with} ~ \mathbf{w}_t \sim \text{MVN}(\mathbf{0}, \mathbf{Q})
$$


## Constraining a DLM

In practice, we often make $\mathbf{G}_t$ time invariant 

$$
\mathbf{\Theta}_t = \mathbf{G} \mathbf{\Theta}_{t-1} + \mathbf{w}_t
$$

or assume $\mathbf{G}_t$ is the identity matrix $\mathbf{I}$

$$
\begin{align}
  \mathbf{\Theta}_t &= \mathbf{I} \mathbf{\Theta}_{t-1} + \mathbf{w}_t \\
                    &= \mathbf{\Theta}_{t-1} + \mathbf{w}_t
\end{align}
$$

In the latter case, the parameters follow a random walk over time


## DLM in state-space form

Observation model relates covariates to data

$$
y_t = \mathbf{X}^{\top}_t \mathbf{\Theta}_t + e_t
$$

State model determines how the parameters "evolve" over time

$$
\mathbf{\Theta}_t = \mathbf{G} \mathbf{\Theta}_{t-1} + \mathbf{w}_t
$$




## Random walk observed with error

$$
y_t = \mu + f_t + e_t ~ \text{with} ~ e_t \sim \text{N}(0, \sigma) \\
f_t = f_{t-1} + w_t ~ \text{with} ~ w_t \sim \text{N}(0, \gamma) \\
\Downarrow \\
y_t = a + x_t + v_t ~ \text{with} ~ v_t \sim \text{N}(0, R) \\
x_t = x_{t-1} + w_t ~ \text{with} ~ w_t \sim \text{N}(0, Q)
$$


